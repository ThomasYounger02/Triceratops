{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19fcd0ba",
   "metadata": {},
   "source": [
    "# Extract\n",
    "## csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "\n",
    "#统一调整数据格式\n",
    "df = pd.read_csv('../data/data.csv', dtype=str)\n",
    "\n",
    "#跳过固定行数\n",
    "df = pd.read_csv('../data/data.csv', skiprows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828615a",
   "metadata": {},
   "source": [
    "## 检查-问题定位-方案-检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b51cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失值检查\n",
    "df_projects.isnull().sum()\n",
    "\n",
    "#横向检查\n",
    "df_population.isnull().sum(axis=1)\n",
    "\n",
    "#检查横向有缺失的值\n",
    "df_population[df_population.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e33e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lines(n, file_name):\n",
    "    f = open(file_name)\n",
    "    for i in range(n):\n",
    "        print(f.readline())\n",
    "    f.close()\n",
    "    \n",
    "print_lines(1, 'population_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833da8da",
   "metadata": {},
   "source": [
    "## json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read in the JSON file\n",
    "with open('data.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# print the first record in the JSON file\n",
    "print(json_data[0])\n",
    "print('\\n')\n",
    "\n",
    "# show that JSON data is essentially a dictionary\n",
    "print(json_data[0]['Col Name1'])\n",
    "print(json_data[0]['Col Name2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98467989",
   "metadata": {},
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11988bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the BeautifulSoup library\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# open the population_data.xml file and load into Beautiful Soup\n",
    "with open(\"population_data.xml\") as fp:\n",
    "    soup = BeautifulSoup(fp, \"lxml\") # lxml is the Parser type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = {'Country or Area':[], 'Year':[], 'Item':[], 'Value':[]}\n",
    "\n",
    "for record in soup.find_all('record'):\n",
    "    for record in record.find_all('field'):\n",
    "        data_dictionary[record['name']].append(record.text)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dictionary)\n",
    "df = df.pivot(index='Country or Area', columns='Year', values='Value')\n",
    "df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cba6ef",
   "metadata": {},
   "source": [
    "## SQLite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9976b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# connect to the database\n",
    "conn = sqlite3.connect('population_data.db')\n",
    "\n",
    "# run a query\n",
    "pd.read_sql('SELECT * FROM population_data', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0a142",
   "metadata": {},
   "source": [
    "## QLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "### \n",
    "# create a database engine \n",
    "# to find the correct file path, use the python os library:\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "#\n",
    "###\n",
    "\n",
    "engine = create_engine('sqlite:////home/workspace/3_sql_exercise/population_data.db')\n",
    "pd.read_sql(\"SELECT * FROM population_data\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6439e4f",
   "metadata": {},
   "source": [
    "## TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d52845",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://api.worldbank.org/v2/countries/br;cn;us;de/indicators/SP.POP.TOTL/?format=json&per_page=1000'\n",
    "r = requests.get(url)\n",
    "r.json()\n",
    "\n",
    "pd.DataFrame(r.json()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b44cf9",
   "metadata": {},
   "source": [
    "# Transform\n",
    "## Combining\n",
    "\n",
    "concat-metl-merge\n",
    "\n",
    "wide format to a long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])\n",
    "df_melt = pd.melt(df, id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'], var_name='year', value_name='GDP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8923bac0",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2687af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['Official Country Name'] = df_projects['countryname'].str.split(';').str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166560ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_country_abbrev_dict.update(country_not_found_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['Country Code'] = df_projects['Official Country Name'].apply(lambda x: project_country_abbrev_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4a2a4",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nafta = df_indicator[(df_indicator['Country Name'] == 'Canada') | \n",
    "             (df_indicator['Country Name'] == 'United States') | \n",
    "            (df_indicator['Country Name'] == 'Mexico')].iloc[:,]\n",
    "\n",
    "df_nafta.sum(axis=0)[keepcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441cd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['totalamt'] = pd.to_numeric(projects['totalamt'].str.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e891f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['totalamt'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e57f7",
   "metadata": {},
   "source": [
    "## Parsing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "parsed_date = pd.to_datetime('January 1st, 2017')\n",
    "parsed_date\n",
    "\n",
    "parsed_date.month\n",
    "parsed_date.year\n",
    "parsed_date.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8fa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_date = pd.to_datetime('5/3/2017 5:30')   #in the United States, dates are given with the month first and then the day. That is what pandas expects by default\n",
    "parsed_date = pd.to_datetime('3/5/2017 5:30', format='%d/%m/%Y %H:%M')\n",
    "parsed_date = pd.to_datetime('5/3/2017 5:30', format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['boardapprovaldate'] = pd.to_datetime(df_projects['boardapprovaldate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_projects.groupby('approvalyear')['totalamt'].sum().plot(x='approvalyear', y='totalamt',\n",
    "                                                          title ='Total Amount Approved per Year')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('amount $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1505397",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodings.aliases import aliases\n",
    "\n",
    "alias_values = set(aliases.values())\n",
    "\n",
    "for encoding in set(aliases.values()):\n",
    "    try:\n",
    "        df=pd.read_csv(\"mystery.csv\", encoding=encoding)\n",
    "        print('successful', encoding)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc1f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the chardet library\n",
    "!pip install chardet\n",
    "\n",
    "# import the chardet library\n",
    "import chardet \n",
    "\n",
    "# use the detect method to find the encoding\n",
    "# 'rb' means read in the file as binary\n",
    "with open(\"mystery.csv\", 'rb') as file:\n",
    "    print(chardet.detect(file.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68834e55",
   "metadata": {},
   "source": [
    "## Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c45c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#均值填充\n",
    "df_melt['GDP_filled'] = df_melt.groupby(\"Country Name\").transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "#forward\n",
    "df_melt['GDP_ffill'] = df_melt.groupby(\"Country Name\").transform(lambda x: x.fillna(method='ffill'))['GDP']\n",
    "\n",
    "#backward\n",
    "df_melt['GDP_bfill'] = df_melt.groupby(\"Country Name\").transform(lambda x: x.fillna(method='bfill'))['GDP']\n",
    "\n",
    "#forward+backward\n",
    "df_melt['GDP_ff_bf'] = df_melt.sort_values('year').groupby('Country Name')['GDP'].fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e92f47",
   "metadata": {},
   "source": [
    "## Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['countryname'].str.contains('Socialist Federal Republic of Yugoslavia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['countryname'].apply(lambda x: x in countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "republics['boardapprovaldate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51cb7b8",
   "metadata": {},
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则\n",
    "sector['sector1'] = sector['sector1'].replace('^(\\(Historic\\))', '', regex=True)\n",
    "\n",
    "# 新的一行\n",
    "sector.loc[:,'sector1_aggregates'] = sector['sector1']\n",
    "\n",
    "# 替换\n",
    "sector.loc[sector['sector1_aggregates'].str.contains('Energy', re.IGNORECASE).replace(np.nan, False),'sector1_aggregates'] = 'Energy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7e2c2",
   "metadata": {},
   "source": [
    "# Outliets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data sets so that they are in long format\n",
    "gdp_melt = gdp.melt(id_vars=['Country Name'], \n",
    "                    var_name='year', \n",
    "                    value_name='gdp')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing gdp values\n",
    "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.plot('population', kind='box')\n",
    "\n",
    "# remove non countries from the data\n",
    "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
    "\n",
    "list(set(population_outliers['Country Name']).intersection(gdp_outliers['Country Name']))\n",
    "\n",
    "list(set(population_outliers['Country Name']) - set(gdp_outliers['Country Name']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code cell below\n",
    "x = list(df_2016['population'])\n",
    "y = list(df_2016['gdp'])\n",
    "text = df_2016['Country Name']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.scatter(x, y)\n",
    "plt.title('GDP vs Population')\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('GDP')\n",
    "for i, txt in enumerate(text):\n",
    "    ax.annotate(txt, (x[i],y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74355246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# fit a linear regression model on the population and gdp data\n",
    "model = LinearRegression()\n",
    "model.fit(df_2016['population'].values.reshape(-1, 1), df_2016['gdp'].values.reshape(-1, 1))\n",
    "\n",
    "# plot the data along with predictions from the linear regression model\n",
    "inputs = np.linspace(1, 2000000000, num=50)\n",
    "predictions = model.predict(inputs.reshape(-1,1))\n",
    "\n",
    "df_2016.plot('population', 'gdp', kind='scatter')\n",
    "plt.plot(inputs, predictions)\n",
    "print(model.predict(1000000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer():\n",
    "    # TODO: Complete the normalizer class\n",
    "    # The normalizer class receives a dataframe as its only input for initialization\n",
    "    # For example, the data frame might contain gdp and population data in two separate columns\n",
    "    # Follow the TODOs in each section\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        \n",
    "        # TODO: complete the init function. \n",
    "        # Assume the dataframe has an unknown number of columns like [['gdp', 'population']] \n",
    "        # iterate through each column calculating the min and max for each column\n",
    "        # append the results to the params attribute list\n",
    "        \n",
    "        # For example, take the gdp column and calculate the minimum and maximum\n",
    "        # Put these results in a list [minimum, maximum]\n",
    "        # Append the list to the params variable\n",
    "        # Then take the population column and do the same\n",
    "        \n",
    "        # HINT: You can put your x_min_max() function as part of this class and use it\n",
    "        \n",
    "        self.params = []\n",
    "\n",
    "        for column in dataframe.columns:\n",
    "            self.params.append(x_min_max(dataframe[column]))\n",
    "            \n",
    "    def x_min_max(data):\n",
    "        # TODO: complete the x_min_max method\n",
    "        # HINT: You can use the same function defined earlier in the exercise\n",
    "        minimum = min(data)\n",
    "        maximum = max(data)\n",
    "        return minimum, maximum\n",
    "\n",
    "    def normalize_data(self, x):\n",
    "        # TODO: complete the normalize_data method\n",
    "        # The function receives a data point as an input and then outputs the normalized version\n",
    "        # For example, if an input data point of [gdp, population] were used. Then the output would\n",
    "        # be the normalized version of the [gdp, population] data point\n",
    "        # Put the results in the normalized variable defined below\n",
    "        \n",
    "        # Assume that the columns in the dataframe used to initialize an object are in the same\n",
    "        # order as this data point x\n",
    "        \n",
    "        # HINT: You cannot use the normalize_data function defined earlier in the exercise.\n",
    "        # You'll need to iterate through the individual values in the x variable        \n",
    "        # Use the params attribute where the min and max values are stored \n",
    "        normalized = []\n",
    "        for i, value in enumerate(x):\n",
    "            x_max = self.params[i][1]\n",
    "            x_min = self.params[i][0]\n",
    "            normalized.append((x[i] - x_min) / (x_max - x_min))\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea9f37",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[column].apply(lambda x: create_multiples(x, num_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new_features.tolist(), columns = column_name_generator(column, num_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code cell - there is nothing for you to do in this code cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# read in the projects data set and do basic wrangling \n",
    "gdp = pd.read_csv('../data/gdp_data.csv', skiprows=4)\n",
    "gdp.drop(['Unnamed: 62', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "population = pd.read_csv('../data/population_data.csv', skiprows=4)\n",
    "population.drop(['Unnamed: 62', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Reshape the data sets so that they are in long format\n",
    "gdp_melt = gdp.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                    var_name='year', \n",
    "                    value_name='gdp')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing gdp values\n",
    "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby(['Country Name', 'Country Code'])['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "population_melt = population.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                                  var_name='year', \n",
    "                                  value_name='population')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing population values\n",
    "population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_indicator = gdp_melt.merge(population_melt, on=('Country Name', 'Country Code', 'year'))\n",
    "\n",
    "# filter out values that are not countries\n",
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    " 'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area',\n",
    " 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_indicator  = df_indicator[~df_indicator['Country Name'].isin(non_countries)]\n",
    "df_indicator.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_indicator.columns = ['countryname', 'countrycode', 'year', 'gdp', 'population']\n",
    "\n",
    "# output the first few rows of the data frame\n",
    "df_indicator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code cell - there is nothing for you to do here \n",
    "\n",
    "!pip install pycountry\n",
    "from pycountry import countries\n",
    "\n",
    "# read in the projects data set with all columns type string\n",
    "df_projects = pd.read_csv('../data/projects_data.csv', dtype=str)\n",
    "df_projects.drop(['Unnamed: 56'], axis=1, inplace=True)\n",
    "\n",
    "df_projects['countryname'] = df_projects['countryname'].str.split(';').str.get(0)\n",
    "\n",
    "# set up the libraries and variables\n",
    "from collections import defaultdict\n",
    "country_not_found = [] # stores countries not found in the pycountry library\n",
    "project_country_abbrev_dict = defaultdict(str) # set up an empty dictionary of string values\n",
    "\n",
    "# iterate through the country names in df_projects. \n",
    "# Create a dictionary mapping the country name to the alpha_3 ISO code\n",
    "for country in df_projects['countryname'].drop_duplicates().sort_values():\n",
    "    try: \n",
    "        # look up the country name in the pycountry library\n",
    "        # store the country name as the dictionary key and the ISO-3 code as the value\n",
    "        project_country_abbrev_dict[country] = countries.lookup(country).alpha_3\n",
    "    except:\n",
    "        # If the country name is not in the pycountry library, then print out the country name\n",
    "        # And store the results in the country_not_found list\n",
    "        country_not_found.append(country)\n",
    "        \n",
    "# run this code cell to load the dictionary\n",
    "\n",
    "country_not_found_mapping = {'Co-operative Republic of Guyana': 'GUY',\n",
    "             'Commonwealth of Australia':'AUS',\n",
    "             'Democratic Republic of Sao Tome and Prin':'STP',\n",
    "             'Democratic Republic of the Congo':'COD',\n",
    "             'Democratic Socialist Republic of Sri Lan':'LKA',\n",
    "             'East Asia and Pacific':'EAS',\n",
    "             'Europe and Central Asia': 'ECS',\n",
    "             'Islamic  Republic of Afghanistan':'AFG',\n",
    "             'Latin America':'LCN',\n",
    "              'Caribbean':'LCN',\n",
    "             'Macedonia':'MKD',\n",
    "             'Middle East and North Africa':'MEA',\n",
    "             'Oriental Republic of Uruguay':'URY',\n",
    "             'Republic of Congo':'COG',\n",
    "             \"Republic of Cote d'Ivoire\":'CIV',\n",
    "             'Republic of Korea':'KOR',\n",
    "             'Republic of Niger':'NER',\n",
    "             'Republic of Kosovo':'XKX',\n",
    "             'Republic of Rwanda':'RWA',\n",
    "              'Republic of The Gambia':'GMB',\n",
    "              'Republic of Togo':'TGO',\n",
    "              'Republic of the Union of Myanmar':'MMR',\n",
    "              'Republica Bolivariana de Venezuela':'VEN',\n",
    "              'Sint Maarten':'SXM',\n",
    "              \"Socialist People's Libyan Arab Jamahiriy\":'LBY',\n",
    "              'Socialist Republic of Vietnam':'VNM',\n",
    "              'Somali Democratic Republic':'SOM',\n",
    "              'South Asia':'SAS',\n",
    "              'St. Kitts and Nevis':'KNA',\n",
    "              'St. Lucia':'LCA',\n",
    "              'St. Vincent and the Grenadines':'VCT',\n",
    "              'State of Eritrea':'ERI',\n",
    "              'The Independent State of Papua New Guine':'PNG',\n",
    "              'West Bank and Gaza':'PSE',\n",
    "              'World':'WLD'}\n",
    "\n",
    "project_country_abbrev_dict.update(country_not_found_mapping)\n",
    "\n",
    "df_projects['countrycode'] = df_projects['countryname'].apply(lambda x: project_country_abbrev_dict[x])\n",
    "\n",
    "df_projects['boardapprovaldate'] = pd.to_datetime(df_projects['boardapprovaldate'])\n",
    "\n",
    "df_projects['year'] = df_projects['boardapprovaldate'].dt.year.astype(str).str.slice(stop=4)\n",
    "\n",
    "df_projects['totalamt'] = pd.to_numeric(df_projects['totalamt'].str.replace(',',\"\"))\n",
    "\n",
    "df_projects = df_projects[['id', 'countryname', 'countrycode', 'totalamt', 'year']]\n",
    "\n",
    "df_projects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171a6cf",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_json('df_merged_json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744443a",
   "metadata": {},
   "source": [
    "## sqllite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# TODO: output the df_merged dataframe to a SQL table called 'merged'.\n",
    "# HINT: Use the to_sql() method\n",
    "# HINT: Use the conn variable for the connection parameter\n",
    "# HINT: You can use the if_exists parameter like if_exists='replace' to replace a table if it already exists\n",
    "\n",
    "df_merged.to_sql('merged', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07611ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit any changes to the database and close the connection to the database\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the data base\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# drop the test table in case it already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS test\")\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "cur.execute(\"CREATE TABLE test (project_id TEXT PRIMARY KEY, countryname TEXT, countrycode TEXT, totalamt REAL, year INTEGER);\")\n",
    "\n",
    "# insert a value into the test table\n",
    "cur.execute(\"INSERT INTO test (project_id, countryname, countrycode, totalamt, year) VALUES ('a', 'Brazil', 'BRA', '100,000', 1970);\")\n",
    "\n",
    "# commit changes made to the database\n",
    "conn.commit()\n",
    "\n",
    "# select all from the test table\n",
    "cur.execute(\"SELECT * FROM test\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit any changes and close the data base\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98927b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, values in df_projects.iterrows():\n",
    "    project_id, countryname, countrycode, totalamt, year = values\n",
    "    \n",
    "    if totalamt == 'nan':\n",
    "        totalamt = 0\n",
    "    if year == 'nan':\n",
    "        year = 0\n",
    "    \n",
    "    sql_string = 'INSERT INTO projects (project_id, countryname, countrycode, totalamt, year) VALUES (\"{}\", \"{}\", \"{}\", {}, {});'.format(project_id, countryname, countrycode, totalamt, year)\n",
    "    cur.execute(sql_string)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161496e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: insert gdp values into the gdp table\n",
    "for index, values in df_indicator[['countryname', 'countrycode', 'year', 'gdp']].iterrows():\n",
    "    countryname, countrycode, year, gdp = values\n",
    "        \n",
    "    sql_string = 'INSERT INTO gdp (countryname, countrycode, year, gdp) VALUES (\"{}\", \"{}\", {}, {});'.format(countryname, countrycode, year, gdp)\n",
    "    cur.execute(sql_string)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc04e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: insert population values into the population table\n",
    "for index, values in df_indicator[['countryname', 'countrycode', 'year', 'population']].iterrows():\n",
    "    countryname, countrycode, year, population = values\n",
    "        \n",
    "    sql_string = 'INSERT INTO population (countryname, countrycode, year, population) VALUES (\"{}\", \"{}\", {}, {});'.format(countryname, countrycode, year, population)\n",
    "    cur.execute(sql_string)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdac592",
   "metadata": {},
   "source": [
    "# Pipe line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to create a database and a table, called gdp, to hold the gdp data\n",
    "# You do not need to change anything in this code cell\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# drop the test table in case it already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS gdp\")\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "cur.execute(\"CREATE TABLE gdp (countryname TEXT, countrycode TEXT, year INTEGER, gdp REAL, PRIMARY KEY (countrycode, year));\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9658f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for reading in one line at a time\n",
    "# generators are useful for data sets that are too large to fit in RAM\n",
    "# You do not need to change anything in this code cell\n",
    "def extract_lines(file):\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d947393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill out the code wherever you find a TODO in this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# transform the indicator data\n",
    "def transform_indicator_data(data, colnames):\n",
    "    \n",
    "    # get rid of quote marks\n",
    "    for i, datum in enumerate(data):\n",
    "        data[i] = datum.replace('\"','')\n",
    "    \n",
    "    country = data[0]\n",
    "    \n",
    "    # filter out values that are not countries\n",
    "    non_countries = ['World',\n",
    "     'High income',\n",
    "     'OECD members',\n",
    "     'Post-demographic dividend',\n",
    "     'IDA & IBRD total',\n",
    "     'Low & middle income',\n",
    "     'Middle income',\n",
    "     'IBRD only',\n",
    "     'East Asia & Pacific',\n",
    "     'Europe & Central Asia',\n",
    "     'North America',\n",
    "     'Upper middle income',\n",
    "     'Late-demographic dividend',\n",
    "     'European Union',\n",
    "     'East Asia & Pacific (excluding high income)',\n",
    "     'East Asia & Pacific (IDA & IBRD countries)',\n",
    "     'Euro area',\n",
    "     'Early-demographic dividend',\n",
    "     'Lower middle income',\n",
    "     'Latin America & Caribbean',\n",
    "     'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    "     'Latin America & Caribbean (excluding high income)',\n",
    "     'Europe & Central Asia (IDA & IBRD countries)',\n",
    "     'Middle East & North Africa',\n",
    "     'Europe & Central Asia (excluding high income)',\n",
    "     'South Asia (IDA & IBRD)',\n",
    "     'South Asia',\n",
    "     'Arab World',\n",
    "     'IDA total',\n",
    "     'Sub-Saharan Africa',\n",
    "     'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    "     'Sub-Saharan Africa (excluding high income)',\n",
    "     'Middle East & North Africa (excluding high income)',\n",
    "     'Middle East & North Africa (IDA & IBRD countries)',\n",
    "     'Central Europe and the Baltics',\n",
    "     'Pre-demographic dividend',\n",
    "     'IDA only',\n",
    "     'Least developed countries: UN classification',\n",
    "     'IDA blend',\n",
    "     'Fragile and conflict affected situations',\n",
    "     'Heavily indebted poor countries (HIPC)',\n",
    "     'Low income',\n",
    "     'Small states',\n",
    "     'Other small states',\n",
    "     'Not classified',\n",
    "     'Caribbean small states',\n",
    "     'Pacific island small states']\n",
    "    \n",
    "    if country not in non_countries:\n",
    "        data_array = np.array(data, ndmin=2)\n",
    "        data_array.reshape(1, 63)\n",
    "        df = pd.DataFrame(data_array, columns=colnames).replace('', np.nan)\n",
    "        df.drop(['\\n', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "\n",
    "        # Reshape the data sets so that they are in long format\n",
    "        df_melt = df.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                            var_name='year', \n",
    "                            value_name='gdp')\n",
    "        \n",
    "        results = []\n",
    "        for index, row in df_melt.iterrows():\n",
    "            country, countrycode, year, gdp = row\n",
    "            if str(gdp) != 'nan':\n",
    "                results.append([country, countrycode, year, gdp])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0353a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill out the code wherever you find a TODO in this cell\n",
    "\n",
    "def load_indicator_data(results):\n",
    "    conn = sqlite3.connect('worldbank.db')\n",
    "    cur = conn.cursor()\n",
    "    if results:\n",
    "        for result in results:\n",
    "            countryname, countrycode, year, gdp = result\n",
    "\n",
    "            sql_string = 'INSERT INTO gdp (countryname, countrycode, year, gdp) VALUES (\"{}\", \"{}\", {}, {});'.format(countryname, countrycode, year, gdp)\n",
    "\n",
    "            # connect to database and execute query\n",
    "            try:\n",
    "                cur.execute(sql_string)\n",
    "            except Exception as e:\n",
    "                print('error occurred:', e, result)\n",
    "            \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc71ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this code cell to run the ETL pipeline\n",
    "# You do not need to change anything in this cell\n",
    "with open('../data/gdp_data.csv') as f:\n",
    "    for line in extract_lines(f):\n",
    "        data = line.split(',')\n",
    "        if len(data) == 63:\n",
    "            if data[0] == '\"Country Name\"':\n",
    "                colnames = []\n",
    "                # get rid of quote marks\n",
    "                for i, datum in enumerate(data):\n",
    "                    colnames.append(datum.replace('\"',''))\n",
    "            else:\n",
    "                # transform and load the line of indicator data\n",
    "                results = transform_indicator_data(data, colnames)\n",
    "                load_indicator_data(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3210ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this code cell to output the values in the gdp table\n",
    "# You do not need to change anything in this cell\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "df = pd.read_sql(\"SELECT * FROM gdp\", con=conn)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460abd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
